# Web Crawling Project

Welcome to the Web Crawling Project! This project is designed to help you extract and analyze data from websites efficiently.

## Table of Contents

- [Introduction](#introduction)
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)

## Introduction

Web crawling, also known as web scraping, is the process of automatically extracting information from websites. This project provides tools and scripts to facilitate web crawling tasks.

## Features

- **Current Feature**: Extract Images from html

## Installation

To get started with the Web Crawling Project, follow these steps:

1. Clone the repository:

  ```sh
  git clone https://github.com/Geez14/WebCrawler.git
  ```

2. Navigate to the project directory:

  ```sh
  cd webcrawling
  ```

3. Install the required dependencies:

  ```sh
  pip install -r requirements.txt
  ```

## Usage

To run the web crawler, use the following command:

```sh
python src/main.py
```

## Contributing

We welcome contributions to the Web Crawling Project! If you have any ideas, suggestions, or bug reports, please open an issue or submit a pull request.

---
